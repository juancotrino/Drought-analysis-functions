{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.strptime(\"21-06-2014\", \"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.strptime(\"07-07-2014\", \"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in date_generated:\n",
    "    date_range.append(date.strftime(\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20140621',\n",
       " '20140622',\n",
       " '20140623',\n",
       " '20140624',\n",
       " '20140625',\n",
       " '20140626',\n",
       " '20140627',\n",
       " '20140628',\n",
       " '20140629',\n",
       " '20140630',\n",
       " '20140701',\n",
       " '20140702',\n",
       " '20140703',\n",
       " '20140704',\n",
       " '20140705',\n",
       " '20140706']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    " \n",
    "start = datetime.strptime(\"01-01-2018\", \"%d-%m-%Y\")\n",
    "end = datetime.strptime(\"04-01-2018\", \"%d-%m-%Y\")\n",
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days + 1)]\n",
    "date_range = []\n",
    "\n",
    "for date in date_generated:\n",
    "    date_range.append(date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-01-01', '2018-01-02']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    " \n",
    "start = datetime.strptime(\"01-01-2018\", \"%d-%m-%Y\")\n",
    "end = datetime.strptime(\"02-01-2018\", \"%d-%m-%Y\")\n",
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days + 1)]\n",
    "date_range = []\n",
    "\n",
    "for date in date_generated:\n",
    "    date_range.append(date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-01-01']\n",
      "['2018-01-01', '2018-01-02']\n",
      "['2018-01-01', '2018-01-02', '2018-01-03']\n",
      "['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04']\n",
      "['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    " \n",
    "start = datetime.strptime(\"01-01-2018\", \"%d-%m-%Y\")\n",
    "end = datetime.strptime(\"05-01-2018\", \"%d-%m-%Y\")\n",
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days + 1)]\n",
    "date_range = []\n",
    "\n",
    "for date in date_generated:\n",
    "    date_range.append(date.strftime(\"%Y-%m-%d\"))\n",
    "    print(date_range[:])\n",
    "\n",
    "#print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180101\n",
      "2018-01-01 00:00:00\n",
      "20180102\n",
      "2018-01-02 00:00:00\n",
      "2019-12-02 08:44:17 ECMWF API python library 1.5.4\n",
      "2019-12-02 08:44:17 ECMWF API at https://api.ecmwf.int/v1\n",
      "2019-12-02 08:44:19 Welcome Juan Manuel Cotrino Palma\n",
      "2019-12-02 08:44:20 In case of problems, please check https://confluence.ecmwf.int/display/WEBAPI/Web+API+FAQ or contact servicedesk@ecmwf.int\n",
      "2019-12-02 08:44:21 Request submitted\n",
      "2019-12-02 08:44:21 Request id: 5de51535cad519329a16dbcb\n",
      "2019-12-02 08:44:21 Request is submitted\n",
      "2019-12-02 08:44:23 Request is queued\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b3e1cbb2af20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;34m\"type\"\u001b[0m   \u001b[1;33m:\u001b[0m \u001b[1;34m\"fc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;34m\"format\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m\"netcdf\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;34m\"target\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m\"tp_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".nc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     })\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\Hapi_env\\lib\\site-packages\\ecmwfapi\\api.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAPIRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"datasets/%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\Hapi_env\\lib\\site-packages\\ecmwfapi\\api.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, request, target)\u001b[0m\n\u001b[0;32m    461\u001b[0m                 \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Request is %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\Hapi_env\\lib\\site-packages\\ecmwfapi\\api.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sleeping %s second(s)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ecmwfapi import ECMWFDataServer\n",
    "from datetime import datetime, timedelta\n",
    " \n",
    "start = datetime.strptime(\"01-01-2018\", \"%d-%m-%Y\")\n",
    "end = datetime.strptime(\"02-01-2018\", \"%d-%m-%Y\")\n",
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days + 1)]\n",
    "date_range = []\n",
    "\n",
    "for date in date_generated:\n",
    "    date_range.append(date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "for date in date_generated:\n",
    "    print str(date.strftime(\"%Y%m%d\"))\n",
    "    print str(date)\n",
    "\n",
    "    \n",
    "for date1 in date_range:\n",
    "    server = ECMWFDataServer()\n",
    "    server.retrieve({\n",
    "        \"class\"  : \"ei\",\n",
    "        \"dataset\": \"interim\",\n",
    "        \"date\"   : str(date.strftime(\"%Y-%m-%d\")),\n",
    "        \"expver\" : \"1\",\n",
    "        \"grid\"   : \"0.75/0.75\",\n",
    "        \"levtype\": \"sfc\",\n",
    "        \"param\"  : \"228.128\",\n",
    "        \"step\"   : \"12\",\n",
    "        \"stream\" : \"oper\",\n",
    "        \"time\"   : \"00:00:00/12:00:00\",\n",
    "        \"type\"   : \"fc\",\n",
    "        \"format\" : \"netcdf\",\n",
    "        \"target\" : \"tp_\" + date.strftime(\"%Y%m%d\") + \".nc\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name __pdoc__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0f787a5fb65b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate2num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\Hapi_env\\lib\\site-packages\\netCDF4\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_netCDF4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Need explicit imports for names beginning with underscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_netCDF4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__pdoc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m from ._netCDF4 import (__version__, __netcdf4libversion__, __hdf5libversion__,\n\u001b[0;32m      7\u001b[0m                        \u001b[0m__has_rename_grp__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__has_nc_inq_path__\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name __pdoc__"
     ]
    }
   ],
   "source": [
    "import time, sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from netCDF4 import Dataset, date2num, num2date\n",
    "import numpy as np\n",
    " \n",
    "day = 20180101\n",
    "f_in = 'tp_%d.nc' % day\n",
    "f_out = 'daily-tp_%d.nc' % day\n",
    " \n",
    "d = datetime.strptime(str(day), '%Y%m%d')\n",
    "time_needed = [d + timedelta(hours = 12), d + timedelta(days = 1)]\n",
    " \n",
    "with Dataset(f_in) as ds_src:\n",
    "    var_time = ds_src.variables['time']\n",
    "    time_avail = num2date(var_time[:], var_time.units,\n",
    "            calendar = var_time.calendar)\n",
    " \n",
    "    indices = []\n",
    "    for tm in time_needed:\n",
    "        a = np.where(time_avail == tm)[0]\n",
    "        if len(a) == 0:\n",
    "            sys.stderr.write('Error: precipitation data is missing/incomplete - %s!\\n'\n",
    "                    % tm.strftime('%Y%m%d %H:%M:%S'))\n",
    "            sys.exit(200)\n",
    "        else:\n",
    "            print('Found %s' % tm.strftime('%Y%m%d %H:%M:%S'))\n",
    "            indices.append(a[0])\n",
    " \n",
    "    var_tp = ds_src.variables['tp']\n",
    "    tp_values_set = False\n",
    "    for idx in indices:\n",
    "        if not tp_values_set:\n",
    "            data = var_tp[idx, :, :]\n",
    "            tp_values_set = True\n",
    "        else:\n",
    "            data += var_tp[idx, :, :]\n",
    "         \n",
    "    with Dataset(f_out, mode = 'w', format = 'NETCDF3_64BIT_OFFSET') as ds_dest:\n",
    "        # Dimensions\n",
    "        for name in ['latitude', 'longitude']:\n",
    "            dim_src = ds_src.dimensions[name]\n",
    "            ds_dest.createDimension(name, dim_src.size)\n",
    "            var_src = ds_src.variables[name]\n",
    "            var_dest = ds_dest.createVariable(name, var_src.datatype, (name,))\n",
    "            var_dest[:] = var_src[:]\n",
    "            var_dest.setncattr('units', var_src.units)\n",
    "            var_dest.setncattr('long_name', var_src.long_name)\n",
    " \n",
    "        ds_dest.createDimension('time', None)\n",
    " \n",
    "        # Variables\n",
    "        var = ds_dest.createVariable('time', np.int32, ('time',))\n",
    "        time_units = 'hours since 1900-01-01 00:00:00'\n",
    "        time_cal = 'gregorian'\n",
    "        var[:] = date2num([d], units = time_units, calendar = time_cal)\n",
    "        var.setncattr('units', time_units)\n",
    "        var.setncattr('long_name', 'time')\n",
    "        var.setncattr('calendar', time_cal)\n",
    "        var = ds_dest.createVariable(var_tp.name, np.double, var_tp.dimensions)\n",
    "        var[0, :, :] = data\n",
    "        var.setncattr('units', var_tp.units)\n",
    "        var.setncattr('long_name', var_tp.long_name)\n",
    " \n",
    "        # Attributes\n",
    "        ds_dest.setncattr('Conventions', 'CF-1.6')\n",
    "        ds_dest.setncattr('history', '%s %s'\n",
    "                % (datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                ' '.join(time.tzname)))\n",
    " \n",
    "        print('Done! Daily total precipitation saved in %s' % f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
